---
title: "Malariaverse Workshop \n Calibration"
author: "Pete Winskill"
format:
  revealjs:
    logo: images/malariaverse.gif
    css: images/logo.css
editor: visual
from: markdown+emoji
---

## Welcome back!

Session aims:

-   Understand why we need to "calibrate" a site
-   Understand when we need to calibrate/re-calibrate
-   Introduction to :package:\[cali\] for model calibration
-   Common challenges/issues when calibrating

## Why calibrate

-   Given all the information about a site (vectors, season *Pf*Pr~2-10~ etc...). We still need to make our best estimation of the "baseline" level of transmission.
-   One relatively simple way of doing this is by modifying the modelled baseline until our model output best matches some observations (e.g. *Pf*Pr~2-10~).

## Calibration process

![](images/Calibration_figure1.png){fig-align="center"}

## Calibration process

![](images/Calibration_figure2.gif){fig-align="center"}

## Calibration process

![](images/Calibration_figure3.png){fig-align="center"}

## When to calibrate

-   Calibration or re-calibration is not always required. In general, you will need to calibrate if:

1.  You have created a new site file
2.  You have modified any site inputs that occur before or at the same time as the data you are trying to calibrate to
3.  The data you are calibrating to has changed
4.  There has been a change to an underlying assumption that would impact the disease dynamics in a model run

## Cali {.smaller}

-   We can use :package:[cali](#cali-1) for model calibration.
-   The `calibrate()` function takes a `target`, for example annual *Pf*Pr~2-10~ for the years 2015-2020.
-   The user defines a `summary_function`, a function that takes the raw model output and produces the model estimate corresponding to the `target`. In this case our summary function will summarise the model-estimated *Pf*Pr~2-10~ for the years 2015-2020
-   `calibrate()` will then search a range of EIRs until the outputs of `summary_function` and within a user-defined tolerance of the `target`

## Cali {#cali-1}

-   It is always good practice to run a simulation and test your `summary_function` before using it in `calibrate()` - this will help with debugging.
-   There a lots of other tuning and model options, so please see `?calibrate()` for more detailed information.

## Challenges

-   :package:[cali](#cali-1) is (hopefully) convenient, however it doesn't remove the need to run the model multiple time when calibrating. Therefore be prepared for the process to be lengthy, often requiring calibration runs to be performed on the high performance cluster.

## Challenges

-   Available data and model outputs are not guaranteed to play nicely

![](images/Guinea-Pig-cat.jpg){fig-align="center"}

## Challenges

Sometimes calibration can look good:

![](images/Calibration_good.png){fig-align="center"}

## Challenges

...and sometimes not:

![](images/Calibration_bad.png){fig-align="center"}

## Challenges

-   Calibration can be difficult when results are dominated by stochasticy
  -   low transmission
  -   small populations
  -   calibrating to a sub-group in the population
  -   etc.

## Let's give it a try!

-   Run `mvw::run_tutorial("Calibration")`


![](images/Guinea-Pig-bike.jpg){fig-align="center" width=40% height=40%}
